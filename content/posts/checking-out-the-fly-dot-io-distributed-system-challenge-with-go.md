+++
title = "Fly.io Distributed System Challenge with Go (Part 1)"
author = ["Woosang Kang"]
tags = ["dev", "go"]
categories = ["systems"]
draft = true
+++

Recently, I ran into an instresting challenge on distributed systems provided by [Fly.io](https://fly.io/dist-sys/). After going through a laborious semester trying to get in touch with my [inner Ninja](https://www.cs.cornell.edu/courses/cs5414/2023sp/) of theory and implementation, I thought that it would be a good chance to check my understanding of the field.


## Part 1, 2: Echo / Unique ID Generation {#part-1-2-echo-unique-id-generation}

These parts were really about familiarizing oneself with the [Maelstrom](https://github.com/jepsen-io/maelstrom) testbench, which the challenge utilizes to abstract basic node-level operations (`send`, sync/async `rpc`, etc.).


### Globally-Unique ID Generation {#globally-unique-id-generation}

There could be a different number of approaches one could take to handle this operation in a distributed setting. My implementation was fairly simple. Given that each of the nodes have their own unique ID, each node will keep its own counter. Then, a unique ID can be easily generated by concatenating the node ID with the counter value, which is incremented on each incoming client request.

```go
func generateID(nodeId string) string {
	count++
	return nodeId + strconv.Itoa(count)
}
```

There weren't any complicated logic; in fact, the snippet above was pretty much the gist of it.


## Part 3: Broadcast {#part-3-broadcast}

Things began to ramp up from this section, as now the problems required communication between internal nodes, whereas the previous problems only required exclusive communication between the clients.


### Naive Broadcast {#naive-broadcast}

Here


### Partition Tolerance {#partition-tolerance}

There could be myriads of different reasons a distributed system may fail, and _network partition_ is definitely one of them.


### Efficiency Metrics {#efficiency-metrics}

Maelstrom, the underlying testbench for the challenge, provided a lot of metrics and charts that I could refer to on analyzing the performance of my algorithm.


#### Stable Latency {#stable-latency}


### Optimization #1: Reshaping the Network {#optimization-1-reshaping-the-network}

Closely reviewing the problem description, I saw that I could ignore the `topology` message and create my own.


### Optimization #2: Gossip {#optimization-2-gossip}

```edn
:net {:all {:send-count 9718,
            :recv-count 9715,
            :msg-count 9718,
            :msgs-per-op 5.037843},
    :clients {:send-count 3958, :recv-count 3958, :msg-count 3958},
    :servers {:send-count 5760,
                :recv-count 5757,
                :msg-count 5760,
                :msgs-per-op 2.9860032},
    :valid? true},
```
